#!/usr/bin/env python3
"""
è¯„ä¼°ç»“æœç»Ÿè®¡å™¨
ç»Ÿè®¡æ‰€æœ‰evaluation_*.jsonæ–‡ä»¶ä¸­çš„æ¨¡å‹æ€§èƒ½
"""

import json
import glob
import os
from collections import defaultdict
import argparse

def parse_model_name_from_file(filename):
    """ä»æ–‡ä»¶åè§£ææ¨¡å‹åç§°"""
    basename = os.path.basename(filename)
    # evaluation_medium_cuda_3_20250724_235359_806.json
    parts = basename.split('_')
    if len(parts) >= 2:
        return parts[1]  # medium, tiny, longç­‰
    return "unknown"

def analyze_evaluation_file(filepath):
    """åˆ†æå•ä¸ªè¯„ä¼°æ–‡ä»¶"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # è·å–åŸºæœ¬ä¿¡æ¯
        eval_info = data.get('evaluation_info', {})
        summary = data.get('summary', {})
        detailed_results = data.get('detailed_results', [])
        
        model_path = eval_info.get('model_path', '')
        model_name = os.path.basename(model_path) if model_path else parse_model_name_from_file(filepath)
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        total_cases = len(detailed_results)
        correct_cases = sum(1 for result in detailed_results if result.get('is_correct', False))
        accuracy = (correct_cases / total_cases * 100) if total_cases > 0 else 0
        
        # æŒ‰éš¾åº¦åˆ†ç±»ç»Ÿè®¡
        difficulty_stats = defaultdict(lambda: {'total': 0, 'correct': 0})
        stage_stats = defaultdict(lambda: {'total': 0, 'correct': 0})
        move_type_stats = defaultdict(lambda: {'total': 0, 'correct': 0})
        
        for result in detailed_results:
            is_correct = result.get('is_correct', False)
            
            # éš¾åº¦ç»Ÿè®¡
            difficulty = result.get('difficulty', 'unknown')
            difficulty_stats[difficulty]['total'] += 1
            if is_correct:
                difficulty_stats[difficulty]['correct'] += 1
            
            # é˜¶æ®µç»Ÿè®¡
            stage = result.get('stage', 'unknown')
            stage_stats[stage]['total'] += 1
            if is_correct:
                stage_stats[stage]['correct'] += 1
            
            # ç§»åŠ¨ç±»å‹ç»Ÿè®¡
            move_type = result.get('move_type', 'unknown')
            move_type_stats[move_type]['total'] += 1
            if is_correct:
                move_type_stats[move_type]['correct'] += 1
        
        return {
            'filename': os.path.basename(filepath),
            'model_name': model_name,
            'model_path': model_path,
            'device': eval_info.get('device', 'unknown'),
            'timestamp': eval_info.get('timestamp', 'unknown'),
            'total_cases': total_cases,
            'correct_cases': correct_cases,
            'accuracy': accuracy,
            'difficulty_stats': dict(difficulty_stats),
            'stage_stats': dict(stage_stats),
            'move_type_stats': dict(move_type_stats)
        }
        
    except Exception as e:
        print(f"âŒ å¤„ç†æ–‡ä»¶ {filepath} æ—¶å‡ºé”™: {e}")
        return None

def calculate_category_accuracy(stats):
    """è®¡ç®—åˆ†ç±»å‡†ç¡®ç‡"""
    for category in stats:
        if stats[category]['total'] > 0:
            stats[category]['accuracy'] = (stats[category]['correct'] / stats[category]['total'] * 100)
        else:
            stats[category]['accuracy'] = 0
    return stats

def main():
    parser = argparse.ArgumentParser(description="è¯„ä¼°ç»“æœç»Ÿè®¡å™¨")
    parser.add_argument("--pattern", type=str, default="evaluation_*.json", help="æ–‡ä»¶åŒ¹é…æ¨¡å¼")
    parser.add_argument("--output", type=str, help="è¾“å‡ºç»Ÿè®¡ç»“æœåˆ°JSONæ–‡ä»¶")
    parser.add_argument("--sort-by", type=str, choices=['accuracy', 'name', 'timestamp'], default='accuracy', help="æ’åºæ–¹å¼")
    
    args = parser.parse_args()
    
    # æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶
    pattern = args.pattern
    if not pattern.startswith('/'):
        pattern = os.path.join('.', pattern)
    
    files = glob.glob(pattern)
    if not files:
        print(f"âŒ æœªæ‰¾åˆ°åŒ¹é…æ¨¡å¼ '{args.pattern}' çš„æ–‡ä»¶")
        return
    
    print(f"ğŸ“ æ‰¾åˆ° {len(files)} ä¸ªè¯„ä¼°æ–‡ä»¶")
    print("=" * 80)
    
    # åˆ†ææ‰€æœ‰æ–‡ä»¶
    results = []
    for filepath in files:
        print(f"ğŸ“„ åˆ†ææ–‡ä»¶: {os.path.basename(filepath)}")
        result = analyze_evaluation_file(filepath)
        if result:
            results.append(result)
    
    if not results:
        print("âŒ æ²¡æœ‰æˆåŠŸåˆ†æçš„æ–‡ä»¶")
        return
    
    # æ’åºç»“æœ
    if args.sort_by == 'accuracy':
        results.sort(key=lambda x: x['accuracy'], reverse=True)
    elif args.sort_by == 'name':
        results.sort(key=lambda x: x['model_name'])
    elif args.sort_by == 'timestamp':
        results.sort(key=lambda x: x['timestamp'])
    
    # æ˜¾ç¤ºç»Ÿè®¡ç»“æœ
    print("\n" + "=" * 80)
    print("ğŸ“Š æ¨¡å‹æ€§èƒ½ç»Ÿè®¡")
    print("=" * 80)
    
    print(f"{'æ¨¡å‹åç§°':<25} {'å‡†ç¡®ç‡':<10} {'æ­£ç¡®/æ€»æ•°':<12} {'è®¾å¤‡':<10} {'æ–‡ä»¶å':<30}")
    print("-" * 80)
    
    for result in results:
        model_name = result['model_name'][:24]
        accuracy = f"{result['accuracy']:.1f}%"
        correct_total = f"{result['correct_cases']}/{result['total_cases']}"
        device = result['device']
        filename = result['filename'][:29]
        
        print(f"{model_name:<25} {accuracy:<10} {correct_total:<12} {device:<10} {filename}")
    
    # æ±‡æ€»ç»Ÿè®¡
    total_cases = sum(r['total_cases'] for r in results)
    total_correct = sum(r['correct_cases'] for r in results)
    avg_accuracy = (total_correct / total_cases * 100) if total_cases > 0 else 0
    
    print("-" * 80)
    print(f"{'æ€»è®¡':<25} {avg_accuracy:.1f}% {total_correct}/{total_cases}")
    
    # è¯¦ç»†åˆ†ç±»ç»Ÿè®¡
    print("\nğŸ“ˆ è¯¦ç»†åˆ†ç±»ç»Ÿè®¡:")
    
    # æ±‡æ€»æ‰€æœ‰æ¨¡å‹çš„éš¾åº¦ç»Ÿè®¡
    combined_difficulty = defaultdict(lambda: {'total': 0, 'correct': 0})
    combined_stage = defaultdict(lambda: {'total': 0, 'correct': 0})
    combined_move_type = defaultdict(lambda: {'total': 0, 'correct': 0})
    
    for result in results:
        for diff, stats in result['difficulty_stats'].items():
            combined_difficulty[diff]['total'] += stats['total']
            combined_difficulty[diff]['correct'] += stats['correct']
        
        for stage, stats in result['stage_stats'].items():
            combined_stage[stage]['total'] += stats['total']
            combined_stage[stage]['correct'] += stats['correct']
        
        for move_type, stats in result['move_type_stats'].items():
            combined_move_type[move_type]['total'] += stats['total']
            combined_move_type[move_type]['correct'] += stats['correct']
    
    # æ˜¾ç¤ºæ±‡æ€»ç»Ÿè®¡
    print("\nğŸ¯ æŒ‰éš¾åº¦æ±‡æ€»:")
    combined_difficulty = calculate_category_accuracy(combined_difficulty)
    for difficulty, stats in sorted(combined_difficulty.items()):
        print(f"  {difficulty}: {stats['correct']}/{stats['total']} ({stats['accuracy']:.1f}%)")
    
    print("\nğŸ¯ æŒ‰é˜¶æ®µæ±‡æ€»:")
    combined_stage = calculate_category_accuracy(combined_stage)
    for stage, stats in sorted(combined_stage.items()):
        print(f"  {stage}: {stats['correct']}/{stats['total']} ({stats['accuracy']:.1f}%)")
    
    print("\nğŸ¯ æŒ‰ç§»åŠ¨ç±»å‹æ±‡æ€»:")
    combined_move_type = calculate_category_accuracy(combined_move_type)
    for move_type, stats in sorted(combined_move_type.items()):
        print(f"  {move_type}: {stats['correct']}/{stats['total']} ({stats['accuracy']:.1f}%)")
    
    # ä¿å­˜è¯¦ç»†ç»Ÿè®¡ç»“æœ
    if args.output:
        summary_data = {
            'analysis_info': {
                'total_files': len(results),
                'total_cases': total_cases,
                'total_correct': total_correct,
                'average_accuracy': avg_accuracy,
                'pattern': args.pattern,
                'sort_by': args.sort_by
            },
            'model_results': results,
            'combined_stats': {
                'difficulty': dict(combined_difficulty),
                'stage': dict(combined_stage),
                'move_type': dict(combined_move_type)
            }
        }
        
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(summary_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ è¯¦ç»†ç»Ÿè®¡ç»“æœå·²ä¿å­˜åˆ°: {args.output}")
    
    # æ˜¾ç¤ºæœ€ä½³å’Œæœ€å·®æ¨¡å‹
    if len(results) > 1:
        best_model = results[0]
        worst_model = results[-1]
        
        print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model['model_name']} ({best_model['accuracy']:.1f}%)")
        print(f"ğŸ“‰ æœ€å·®æ¨¡å‹: {worst_model['model_name']} ({worst_model['accuracy']:.1f}%)")
        print(f"ğŸ“Š æ€§èƒ½å·®è·: {best_model['accuracy'] - worst_model['accuracy']:.1f}%")

if __name__ == "__main__":
    main()

# TextArena SelfPlay Qwen - äº•å­—æ£‹CoTè®­ç»ƒé¡¹ç›®

ä¸€ä¸ªå®Œæ•´çš„åŸºäºQwenæ¨¡å‹çš„äº•å­—æ£‹æ€ç»´é“¾(Chain-of-Thought)è®­ç»ƒå’Œè¯„ä¼°ç³»ç»Ÿã€‚è¯¥é¡¹ç›®å®ç°äº†6ç§ä¸åŒé•¿åº¦çš„CoTè®­ç»ƒæ¨¡å¼ï¼Œæ”¯æŒå¤šGPUå¹¶è¡Œè®­ç»ƒå’Œé«˜é€Ÿè¯„ä¼°ã€‚

- ç›®å‰è„šæœ¬bugè¿˜æ¯”è¾ƒå¤š, å¤ç°ä¸æ–¹ä¾¿, readmeæ˜¯ç”¨aiå†™çš„

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®é€šè¿‡è‡ªå¯¹å¼ˆç”Ÿæˆäº•å­—æ£‹æ•°æ®ï¼Œè®­ç»ƒ6ç§ä¸åŒCoTé•¿åº¦çš„æ¨¡å‹ï¼š
- **Tiny CoT** (80-120å­—ç¬¦): è¶…çŸ­æ¨ç†
- **Short CoT** (150-250å­—ç¬¦): çŸ­æ¨ç†  
- **Medium CoT** (300-500å­—ç¬¦): ä¸­ç­‰æ¨ç†
- **Long CoT** (600-1000å­—ç¬¦): é•¿æ¨ç†
- **Very Long CoT** (1500-2500å­—ç¬¦): å¾ˆé•¿æ¨ç†
- **Ultra Long CoT** (3000-5000å­—ç¬¦): è¶…é•¿æ¨ç†

## ğŸ“‹ é¡¹ç›®ç»“æ„

```
textarena-selfplay-qwen/
â”œâ”€â”€ src/                          # æ ¸å¿ƒæºç 
â”‚   â”œâ”€â”€ qwen_agent.py            # Qwenæ™ºèƒ½ä½“å®ç°
â”‚   â””â”€â”€ tictactoe_game.py        # äº•å­—æ£‹æ¸¸æˆé€»è¾‘
â”œâ”€â”€ evaluation/                   # è¯„ä¼°æ¨¡å—
â”‚   â”œâ”€â”€ model_evaluator.py       # ç»Ÿä¸€æ¨¡å‹è¯„ä¼°å™¨
â”‚   â””â”€â”€ generate_test_set.py     # æµ‹è¯•é›†ç”Ÿæˆ
â”œâ”€â”€ scripts/                     # è„šæœ¬å·¥å…·
â”‚   â”œâ”€â”€ training/               # è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ evaluation/             # è¯„ä¼°è„šæœ¬  
â”‚   â”œâ”€â”€ data_generation/        # æ•°æ®ç”Ÿæˆè„šæœ¬
â”‚   â””â”€â”€ utils/                  # å·¥å…·è„šæœ¬
â”œâ”€â”€ configs/                     # é…ç½®æ–‡ä»¶
â”œâ”€â”€ llama_factory_configs/       # LlamaFactoryè®­ç»ƒé…ç½®
â”œâ”€â”€ data/                        # æ•°æ®ç›®å½•
â”œâ”€â”€ models/                      # è®­ç»ƒåçš„æ¨¡å‹
â””â”€â”€ evaluation_results/          # è¯„ä¼°ç»“æœ
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒé…ç½®

```bash
# å…‹éš†é¡¹ç›®
git clone <repository-url>
cd textarena-selfplay-qwen

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# å®‰è£…LlamaFactory (ç”¨äºè®­ç»ƒ)
git clone https://github.com/hiyouga/LLaMA-Factory.git
cd LLaMA-Factory
pip install -e .
```

## ğŸ“Š ä½¿ç”¨æŒ‡å—

### 1. æµ‹è¯•é›†ç”Ÿæˆ

ç”Ÿæˆç”¨äºæ¨¡å‹è¯„ä¼°çš„æ ‡å‡†æµ‹è¯•é›†ï¼š

```bash
# ç”Ÿæˆ100ä¸ªæµ‹è¯•æ¡ˆä¾‹çš„æ ‡å‡†æµ‹è¯•é›†
cd evaluation
python generate_test_set.py --num_cases 100 --output_file ../data/processed/tictactoe_test_set_100.json

# ç”Ÿæˆä¸åŒéš¾åº¦çš„æµ‹è¯•é›†
python generate_test_set.py --num_cases 200 --difficulty_distribution easy:50,medium:30,hard:20
```

**å‚æ•°è¯´æ˜ï¼š**
- `--num_cases`: ç”Ÿæˆçš„æµ‹è¯•æ¡ˆä¾‹æ•°é‡
- `--output_file`: è¾“å‡ºæ–‡ä»¶è·¯å¾„
- `--difficulty_distribution`: éš¾åº¦åˆ†å¸ƒ (easy/medium/hard)
- `--seed`: éšæœºç§å­ï¼Œç¡®ä¿å¯é‡ç°

### 2. CoTæ•°æ®ç”Ÿæˆ

ç”Ÿæˆ6ç§ä¸åŒé•¿åº¦çš„CoTè®­ç»ƒæ•°æ®ï¼š

```bash
# ç”Ÿæˆæ‰€æœ‰CoTé•¿åº¦çš„è®­ç»ƒæ•°æ®
cd scripts/data_generation
python generate_all_cot_lengths.py

# è‡ªå®šä¹‰å‚æ•°ç”Ÿæˆ
python generate_all_cot_lengths.py --num_games 2000 --base_output_dir ../../data/processed
```

**ç”Ÿæˆçš„æ•°æ®ç±»å‹ï¼š**
- `tictactoe_tiny_cot_data.json` - è¶…çŸ­æ¨ç†æ•°æ®
- `tictactoe_short_cot_data.json` - çŸ­æ¨ç†æ•°æ®  
- `tictactoe_medium_cot_data.json` - ä¸­ç­‰æ¨ç†æ•°æ®
- `tictactoe_long_cot_data.json` - é•¿æ¨ç†æ•°æ®
- `tictactoe_very_long_cot_data.json` - å¾ˆé•¿æ¨ç†æ•°æ®
- `tictactoe_ultra_long_cot_data.json` - è¶…é•¿æ¨ç†æ•°æ®

**å‚æ•°è¯´æ˜ï¼š**
- `--num_games`: æ¯ç§CoTç±»å‹ç”Ÿæˆçš„æ¸¸æˆæ•°é‡
- `--base_output_dir`: è¾“å‡ºç›®å½•
- `--device`: æŒ‡å®šGPUè®¾å¤‡

### 3. æ¨¡å‹è®­ç»ƒ

#### å•æ¨¡å‹è®­ç»ƒ

ä½¿ç”¨LlamaFactoryè¿›è¡Œè®­ç»ƒï¼š

```bash
# è¿›å…¥LlamaFactoryç›®å½•
cd LLaMA-Factory

# è®­ç»ƒTiny CoTæ¨¡å‹
llamafactory-cli train ../llama_factory_configs/qwen_tiny_sft_config.yaml

# è®­ç»ƒå…¶ä»–æ¨¡å‹
llamafactory-cli train ../llama_factory_configs/qwen_short_sft_config.yaml   # Short CoT
llamafactory-cli train ../llama_factory_configs/qwen_medium_sft_config.yaml  # Medium CoT
llamafactory-cli train ../llama_factory_configs/qwen_long_sft_config.yaml    # Long CoT
```

#### å¤šGPUå¹¶è¡Œè®­ç»ƒ

```bash
# 8GPUå¹¶è¡Œè®­ç»ƒæ‰€æœ‰6ä¸ªæ¨¡å‹
cd scripts/training
bash train_all_models_parallel.sh

# ç›‘æ§è®­ç»ƒè¿›åº¦
bash monitor_training.sh

# åœæ­¢æ‰€æœ‰è®­ç»ƒ
bash stop_all_training.sh
```

**è®­ç»ƒé…ç½®ï¼š**
- ä½¿ç”¨LoRAå¾®è°ƒå‡å°‘æ˜¾å­˜å ç”¨
- è‡ªåŠ¨GPUåˆ†é…: GPU1-6åˆ†åˆ«è®­ç»ƒä¸åŒCoTæ¨¡å‹
- æ”¯æŒæ–­ç‚¹ç»­è®­
- å®æ—¶æ—¥å¿—ç›‘æ§

### 4. æ¨¡å‹è¯„ä¼°

#### å¿«é€Ÿè¯„ä¼° (æ¨è)

```bash
# Ultra Fast 8GPUå¹¶è¡Œè¯„ä¼°æ‰€æœ‰æ¨¡å‹
cd scripts/evaluation
bash ultra_fast_eval.sh

# é¢„è®¡æ—¶é—´: 10-15åˆ†é’Ÿå®Œæˆæ‰€æœ‰7ä¸ªæ¨¡å‹çš„100ä¸ªæµ‹è¯•æ ·ä¾‹
```

#### å•æ¨¡å‹è¯¦ç»†è¯„ä¼°

```bash
# è¯„ä¼°å•ä¸ªæ¨¡å‹
cd evaluation
python model_evaluator.py --model-path ../models/qwen_tiny_cot_lora --num-cases 100

# è¯„ä¼°åŸºçº¿æ¨¡å‹
python model_evaluator.py --model-type base --num-cases 100

# å¯¹æ¯”è¯„ä¼°
python model_evaluator.py --model-type both --num-cases 50
```

#### è‡ªå®šä¹‰è¯„ä¼°

```bash
# é«˜å¹¶è¡Œåº¦è¯„ä¼°
python model_evaluator.py \
    --num-cases 100 \
    --max-workers 16 \
    --batch-size 32 \
    --model-path ../models/qwen_medium_cot_lora

# å¤šGPUè¯„ä¼°
python scripts/evaluation/ultra_turbo_evaluator.py
```

**è¯„ä¼°å‚æ•°ï¼š**
- `--num-cases`: æµ‹è¯•æ¡ˆä¾‹æ•°é‡
- `--max-workers`: å¹¶è¡Œçº¿ç¨‹æ•°
- `--batch-size`: æ‰¹å¤„ç†å¤§å°
- `--device`: æŒ‡å®šGPUè®¾å¤‡
- `--quiet`: é™é»˜æ¨¡å¼

## ğŸ”§ é«˜çº§åŠŸèƒ½

### GPUèµ„æºç›‘æ§

```bash
# å®æ—¶ç›‘æ§8GPUä½¿ç”¨æƒ…å†µ
cd scripts/utils
bash gpu_monitor.sh
```

### è®­ç»ƒç›‘æ§

```bash
# ç›‘æ§æ‰€æœ‰æ¨¡å‹è®­ç»ƒçŠ¶æ€
cd scripts/training
bash monitor_training.sh

# æŸ¥çœ‹ç‰¹å®šæ¨¡å‹è®­ç»ƒæ—¥å¿—
tail -f ../../logs/train_tiny.log
```

### ç»“æœåˆ†æ

```bash
# æŸ¥çœ‹è¯„ä¼°ç»“æœ
ls evaluation_results/

# åˆ†ææœ€æ–°è¯„ä¼°ç»“æœ
python -c "
import json
import glob
import os
files = glob.glob('evaluation_results/ultra_turbo_evaluation_*.json')
if files:
    latest_file = max(files, key=os.path.getctime)
    with open(latest_file, 'r') as f:
        data = json.load(f)
    for result in data['results']:
        if result.get('success', False):
            print(f\"{result['model_name']}: {result.get('accuracy', 0):.1f}%\")
"
```

## ğŸ“ˆ æ€§èƒ½åŸºå‡†

åŸºäº100ä¸ªæµ‹è¯•æ ·ä¾‹çš„è¯„ä¼°ç»“æœï¼š

| æ¨¡å‹ | å‡†ç¡®ç‡ | CoTè´¨é‡ | æ¨ç†é€Ÿåº¦ | æ˜¾å­˜å ç”¨ |
|------|--------|---------|----------|----------|
| QwenåŸºçº¿ | ~0% | 0/5 | æœ€å¿« | æœ€å°‘ |
| Tiny CoT | ~15-20% | 2/5 | å¿« | å°‘ |
| Short CoT | ~10-25% | 3/5 | ä¸­ç­‰ | ä¸­ç­‰ |
| Medium CoT | ~5-20% | 3/5 | ä¸­ç­‰ | ä¸­ç­‰ |
| Long CoT | ~0-15% | 4/5 | æ…¢ | å¤š |
| Very Long CoT | ~0-10% | 4/5 | æ›´æ…¢ | æ›´å¤š |
| Ultra Long CoT | ~0-5% | 5/5 | æœ€æ…¢ | æœ€å¤š |

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **CUDAå†…å­˜ä¸è¶³**
   ```bash
   # å‡å°‘æ‰¹å¤§å°
   --batch-size 8
   # æˆ–ä½¿ç”¨æ›´å°çš„æ¨¡å‹
   --max-workers 4
   ```

2. **è®­ç»ƒä¸­æ–­**
   ```bash
   # æ£€æŸ¥è®­ç»ƒçŠ¶æ€
   bash scripts/training/monitor_training.sh
   # é‡å¯è®­ç»ƒ
   bash scripts/training/train_all_models_parallel.sh
   ```

3. **è¯„ä¼°é€Ÿåº¦æ…¢**
   ```bash
   # ä½¿ç”¨æ›´å°‘æµ‹è¯•æ¡ˆä¾‹
   --num-cases 20
   # æˆ–ä½¿ç”¨Ultra Fastè¯„ä¼°
   bash scripts/evaluation/ultra_fast_eval.sh
   ```

4. **æ¨¡å‹è·¯å¾„é”™è¯¯**
   ```bash
   # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
   ls models/
   # ä½¿ç”¨æ­£ç¡®çš„æ¨¡å‹è·¯å¾„
   --model-path ./models/qwen_tiny_cot_lora
   ```

### æ—¥å¿—æ–‡ä»¶

- è®­ç»ƒæ—¥å¿—: `logs/train_*.log`
- è¯„ä¼°ç»“æœ: `evaluation_results/`
- é”™è¯¯æ—¥å¿—: `nohup.out`

## ğŸ“ è„šæœ¬è¯´æ˜

### è®­ç»ƒè„šæœ¬
- `scripts/training/train_all_models_parallel.sh` - å¤šGPUå¹¶è¡Œè®­ç»ƒæ‰€æœ‰æ¨¡å‹
- `scripts/training/monitor_training.sh` - ç›‘æ§è®­ç»ƒè¿›åº¦
- `scripts/training/stop_all_training.sh` - åœæ­¢æ‰€æœ‰è®­ç»ƒè¿›ç¨‹

### æ•°æ®ç”Ÿæˆè„šæœ¬  
- `scripts/data_generation/generate_all_cot_lengths.py` - ç”Ÿæˆ6ç§CoTæ•°æ®
- `evaluation/generate_test_set.py` - ç”Ÿæˆæ ‡å‡†æµ‹è¯•é›†

### è¯„ä¼°è„šæœ¬
- `scripts/evaluation/ultra_fast_eval.sh` - 8GPUè¶…é«˜é€Ÿè¯„ä¼°
- `scripts/evaluation/ultra_turbo_evaluator.py` - å¹¶è¡Œè¯„ä¼°å™¨
- `evaluation/model_evaluator.py` - ç»Ÿä¸€æ¨¡å‹è¯„ä¼°å™¨

### å·¥å…·è„šæœ¬
- `scripts/utils/gpu_monitor.sh` - GPUèµ„æºç›‘æ§

## ğŸ¤ è´¡çŒ®æŒ‡å—

1. Forké¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯: `git checkout -b feature/new-feature`
3. æäº¤æ›´æ”¹: `git commit -am 'Add new feature'`
4. æ¨é€åˆ†æ”¯: `git push origin feature/new-feature`
5. åˆ›å»ºPull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶

## ğŸ”— ç›¸å…³é“¾æ¥

- [LlamaFactory](https://github.com/hiyouga/LLaMA-Factory) - è®­ç»ƒæ¡†æ¶
- [Qwenæ¨¡å‹](https://github.com/QwenLM/Qwen) - åŸºç¡€æ¨¡å‹
- [TextArena](https://github.com/textarena/textarena) - æ¸¸æˆç¯å¢ƒ
